{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCzb7ANyxoBP",
        "outputId": "021ca23f-5c1c-4d93-fb3f-5652e49c313f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.135.0-py2.py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Collecting google-auth-httplib2\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Collecting requests_html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Collecting notion_client\n",
            "  Downloading notion_client-2.2.1-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.31.0)\n",
            "Collecting pyquery (from requests_html)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent (from requests_html)\n",
            "  Downloading fake_useragent-1.5.1-py3-none-any.whl (17 kB)\n",
            "Collecting parse (from requests_html)\n",
            "  Downloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting bs4 (from requests_html)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting w3lib (from requests_html)\n",
            "  Downloading w3lib-2.2.1-py3-none-any.whl (21 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests_html)\n",
            "  Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.15.0 (from notion_client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.63.1)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.1.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15.0->notion_client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15.0->notion_client) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.15.0->notion_client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15.0->notion_client) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.15.0->notion_client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.15.0->notion_client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests_html)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (7.2.0)\n",
            "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests_html)\n",
            "  Downloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.66.4)\n",
            "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests_html)\n",
            "  Downloading urllib3-1.26.19-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests_html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->requests_html) (3.3.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests_html) (4.12.3)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests_html) (4.9.4)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests_html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.19.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests_html) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.15.0->notion_client) (1.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests_html) (2.5)\n",
            "Installing collected packages: parse, fake-useragent, appdirs, websockets, w3lib, urllib3, pyee, h11, cssselect, pyquery, pyppeteer, httpcore, bs4, requests_html, httpx, google-auth-httplib2, notion_client, google-api-python-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: google-auth-httplib2\n",
            "    Found existing installation: google-auth-httplib2 0.1.1\n",
            "    Uninstalling google-auth-httplib2-0.1.1:\n",
            "      Successfully uninstalled google-auth-httplib2-0.1.1\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "Successfully installed appdirs-1.4.4 bs4-0.0.2 cssselect-1.2.0 fake-useragent-1.5.1 google-api-python-client-2.135.0 google-auth-httplib2-0.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 notion_client-2.2.1 parse-1.20.2 pyee-11.1.0 pyppeteer-2.0.0 pyquery-2.0.0 requests_html-0.10.0 urllib3-1.26.19 w3lib-2.2.1 websockets-10.4\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages and mount Google Drive\n",
        "!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib requests_html notion_client\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries and define functions\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from requests_html import AsyncHTMLSession\n",
        "from notion_client import Client\n",
        "from urllib.parse import urlparse\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# Imgur credentials\n",
        "IMGUR_CLIENT_ID = '326b12ff922fa0b'\n",
        "\n",
        "# Notion credentials\n",
        "NOTION_TOKEN = 'secret_8sdnrAKx6tCdNwDhu6fjmBmaZf23vaRbGbMGdnyKm5q'\n",
        "DATABASE_ID = '32109f9347b041aa963712d943f572aa'\n",
        "\n",
        "# Google Drive credentials\n",
        "SERVICE_ACCOUNT_FILE = '/content/drive/MyDrive/Colab Notebooks/xtonotion-ff023d1e2552.json'  # Path to the downloaded JSON file\n",
        "FOLDER_ID = '1l4PKOPz-auCi1z0GZOa4Ok7DQ09pXoGv'  # Update this with your folder ID\n",
        "\n",
        "# Scopes for Google Drive API\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive.file']\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"Script started\")\n",
        "\n",
        "# Authenticate and create the Google Drive service\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "drive_service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "# Notion client\n",
        "notion = Client(auth=NOTION_TOKEN)\n",
        "\n",
        "async def scrape_x_link(x_link):\n",
        "    print(f\"Scraping link: {x_link}\")\n",
        "\n",
        "    session = AsyncHTMLSession()\n",
        "    response = await session.get(x_link)\n",
        "    await response.html.arender(sleep=5)  # Render the JavaScript\n",
        "\n",
        "    # Extract post text\n",
        "    post_text = ''\n",
        "    try:\n",
        "        tweet_content = response.html.find('div[data-testid=\"tweetText\"]', first=True)\n",
        "        post_text = tweet_content.text if tweet_content else 'No description available'\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract post text: {e}\")\n",
        "\n",
        "    # Extract author\n",
        "    author = ''\n",
        "    try:\n",
        "        author_tag = response.html.find('div[data-testid=\"User-Name\"] span', first=True)\n",
        "        author = author_tag.text if author_tag else 'Unknown author'\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract author: {e}\")\n",
        "\n",
        "    # Extract images\n",
        "    images = []\n",
        "    try:\n",
        "        image_tags = response.html.find('img[alt=\"Image\"]')\n",
        "        images = [img.attrs['src'] for img in image_tags]\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract images: {e}\")\n",
        "\n",
        "    post_image = images[0] if images else 'https://via.placeholder.com/150'\n",
        "\n",
        "    return post_text, post_image, author, images\n",
        "\n",
        "def upload_image_to_imgur(image_url):\n",
        "    headers = {\"Authorization\": f\"Client-ID {IMGUR_CLIENT_ID}\"}\n",
        "    response = requests.post(\"https://api.imgur.com/3/upload\", headers=headers, data={\"image\": image_url})\n",
        "    if response.status_code == 200:\n",
        "        return response.json()[\"data\"][\"link\"]\n",
        "    else:\n",
        "        print(f\"Failed to upload image to Imgur: {response.status_code}, {response.text}\")\n",
        "        return None\n",
        "\n",
        "def upload_image_to_google_drive(image_url, filename):\n",
        "    try:\n",
        "        # Download the image\n",
        "        image_data = requests.get(image_url).content\n",
        "        with open('/tmp/temp_image.jpg', 'wb') as f:\n",
        "            f.write(image_data)\n",
        "\n",
        "        # Upload to Google Drive with dynamic filename\n",
        "        file_metadata = {\n",
        "            'name': filename,\n",
        "            'parents': [FOLDER_ID]\n",
        "        }\n",
        "        media = MediaFileUpload('/tmp/temp_image.jpg', mimetype='image/jpeg')\n",
        "        file = drive_service.files().create(\n",
        "            body=file_metadata,\n",
        "            media_body=media,\n",
        "            fields='id,webContentLink'\n",
        "        ).execute()\n",
        "\n",
        "        # Make the file public\n",
        "        file_id = file.get('id')\n",
        "        drive_service.permissions().create(\n",
        "            fileId=file_id,\n",
        "            body={'role': 'reader', 'type': 'anyone'}\n",
        "        ).execute()\n",
        "\n",
        "        # Get the direct download link\n",
        "        shareable_link = file['webContentLink']\n",
        "        return shareable_link\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to upload image to Google Drive: {e}\")\n",
        "    return None\n",
        "\n",
        "def generate_filename_from_link(link):\n",
        "    # Replace invalid filename characters with underscores\n",
        "    filename = link.replace('https://', '').replace('/', '_').replace('?', '_').replace('=', '_').replace('&', '_')\n",
        "    return filename\n",
        "\n",
        "def save_to_notion(post_text, post_image, author, category, link):\n",
        "    platform = urlparse(link).netloc\n",
        "    filename = generate_filename_from_link(link)\n",
        "    uploaded_image_url = upload_image_to_imgur(post_image) if post_image != 'https://via.placeholder.com/150' else None\n",
        "\n",
        "    # Save the image to Google Drive as well\n",
        "    google_drive_link = upload_image_to_google_drive(post_image, filename)\n",
        "\n",
        "    data = {\n",
        "        \"parent\": {\"database_id\": DATABASE_ID},\n",
        "        \"properties\": {\n",
        "            \"Title\": {\"title\": [{\"text\": {\"content\": author}}]},\n",
        "            \"Content\": {\"rich_text\": [{\"text\": {\"content\": post_text}}]},\n",
        "            \"Platform\": {\"rich_text\": [{\"text\": {\"content\": platform}}]},\n",
        "            \"Category\": {\"select\": {\"name\": category}},\n",
        "            \"Link\": {\"url\": link}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if uploaded_image_url:\n",
        "        data['properties']['Preview'] = {\n",
        "            \"files\": [{\"name\": \"image\", \"external\": {\"url\": uploaded_image_url}}]\n",
        "        }\n",
        "\n",
        "    print(\"Data to be sent to Notion:\", data)\n",
        "    try:\n",
        "        notion.pages.create(**data)\n",
        "        print(\"Data saved to Notion successfully!\")\n",
        "        print(f\"Image also saved to Google Drive: {google_drive_link}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to save data to Notion: {e}\")\n",
        "\n",
        "async def main():\n",
        "    print(\"Main function started\")\n",
        "    x_link = 'https://x.com/aisolopreneur/status/1806116065866584489?s=52&t=5HGYPwHEzZYlYwwa8QPw9Q'  # Replace with an actual X link for testing\n",
        "    category = 'Test Category'  # Ensure this is a valid select option in your Notion database\n",
        "    print(f\"Scraping link: {x_link} with category: {category}\")\n",
        "    post_text, post_image, author, images = await scrape_x_link(x_link)\n",
        "    print(f\"Scraped data - Text: {post_text}, Image: {post_image}, Author: {author}, Images: {images}\")\n",
        "    save_to_notion(post_text, post_image, author, category, x_link)\n",
        "    print(\"Saved to Notion!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Executing main function\")\n",
        "    asyncio.run(main())\n",
        "    print(\"Main function executed\")\n"
      ],
      "metadata": {
        "id": "3bUnb-ArxtId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17905d17-6b67-44b7-9cc1-25194c76e679"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script started\n",
            "Executing main function\n",
            "Main function started\n",
            "Scraping link: https://x.com/aisolopreneur/status/1806116065866584489?s=52&t=5HGYPwHEzZYlYwwa8QPw9Q with category: Test Category\n",
            "Scraping link: https://x.com/aisolopreneur/status/1806116065866584489?s=52&t=5HGYPwHEzZYlYwwa8QPw9Q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] Starting Chromium download.\n",
            "INFO:pyppeteer.chromium_downloader:Starting Chromium download.\n",
            "100%|██████████| 183M/183M [00:04<00:00, 38.0Mb/s]\n",
            "[INFO] Beginning extraction\n",
            "INFO:pyppeteer.chromium_downloader:Beginning extraction\n",
            "[INFO] Chromium extracted to: /root/.local/share/pyppeteer/local-chromium/1181205\n",
            "INFO:pyppeteer.chromium_downloader:Chromium extracted to: /root/.local/share/pyppeteer/local-chromium/1181205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped data - Text: RIP product designers? Figma just dropped a groundbreaking new AI update today. The 10 most amazing new Figma AI features:, Image: https://pbs.twimg.com/media/GRCc_VfbEAAJ2tf?format=jpg&name=small, Author: The AI Solopreneur, Images: ['https://pbs.twimg.com/media/GRCc_VfbEAAJ2tf?format=jpg&name=small']\n",
            "Data to be sent to Notion: {'parent': {'database_id': '32109f9347b041aa963712d943f572aa'}, 'properties': {'Title': {'title': [{'text': {'content': 'The AI Solopreneur'}}]}, 'Content': {'rich_text': [{'text': {'content': 'RIP product designers? Figma just dropped a groundbreaking new AI update today. The 10 most amazing new Figma AI features:'}}]}, 'Platform': {'rich_text': [{'text': {'content': 'x.com'}}]}, 'Category': {'select': {'name': 'Test Category'}}, 'Link': {'url': 'https://x.com/aisolopreneur/status/1806116065866584489?s=52&t=5HGYPwHEzZYlYwwa8QPw9Q'}, 'Preview': {'files': [{'name': 'image', 'external': {'url': 'https://i.imgur.com/TMUv6ru.jpeg'}}]}}}\n",
            "Data saved to Notion successfully!\n",
            "Image also saved to Google Drive: https://drive.google.com/uc?id=1O7duYKp67nRiFkGrogFYv73opxK8XvQB&export=download\n",
            "Saved to Notion!\n",
            "Main function executed\n"
          ]
        }
      ]
    }
  ]
}